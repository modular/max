# PyTorch inference in MAX

MAX can accelerate the inference of existing PyTorch models. These
examples show several common PyTorch models running in MAX through the
Mojo, Python, and C APIs:

## PyTorch (via TorchScript)

- BERT [with the Python API](./bert-python-torchscript/) and [with the C
API](./bert-c-torchscript/)

- [ResNet50 with the Python API](./resnet50-python-torchscript/)
